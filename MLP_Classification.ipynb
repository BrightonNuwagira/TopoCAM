{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97384784-1522-4153-9fe9-2150d3e97dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results (all_101 only):\n",
      " Feature_Config  AUC_macro  Accuracy  Sensitivity  Specificity  F1_macro\n",
      "       all_101   0.999825  0.995192          1.0     0.987179  0.994858\n",
      "\n",
      "Saved results to: C:\\Users\\Brightons\\Downloads\\Files_breast\\mlp_feature_config_results_breast.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "\n",
    "TRAIN_CSV = r\"C:\\Users\\Brightons\\Downloads\\Files_breast\\Newest_file\\Nonormalization_pneumonia_imagemasked_normcount_train.csv\"\n",
    "VAL_CSV   = r\"C:\\Users\\Brightons\\Downloads\\Files_breast\\Newest_file\\Nonormalization_pneumonia_imagemasked_normcount_val.csv\"\n",
    "TEST_CSV  = r\"C:\\Users\\Brightons\\Downloads\\Files_breast\\Newest_file\\Nonormalization_pneumonia_imagemasked_normcount_test.csv\"\n",
    "\n",
    "LABELS_NPZ = r\"C:\\Users\\Brightons\\Downloads\\pneumoniamnist_224.npz\"\n",
    "\n",
    "# Positive label to use when the task is binary\n",
    "POS_LABEL_FOR_BINARY = 1\n",
    "\n",
    "# Output results file\n",
    "OUT_CSV = \"mlp_feature_config_results_breast.csv\"\n",
    "\n",
    "EXPECTED_NUM_COLS = 101\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val   = pd.read_csv(VAL_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "data = np.load(LABELS_NPZ)\n",
    "y_train, y_val, y_test = data[\"train_labels\"], data[\"val_labels\"], data[\"test_labels\"]\n",
    "y_train = np.ravel(y_train)\n",
    "y_val   = np.ravel(y_val)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "X_train_raw = df_train.values.astype(np.float32)\n",
    "X_val_raw   = df_val.values.astype(np.float32)\n",
    "X_test_raw  = df_test.values.astype(np.float32)\n",
    "\n",
    "assert X_train_raw.shape[1] == EXPECTED_NUM_COLS\n",
    "assert X_val_raw.shape[1]   == EXPECTED_NUM_COLS\n",
    "assert X_test_raw.shape[1]  == EXPECTED_NUM_COLS\n",
    "\n",
    "\n",
    "def macro_specificity_ovr(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Macro-average specificity (TNR) via one-vs-rest per class.\"\"\"\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    specs = []\n",
    "    for c in classes:\n",
    "        y_true_bin = (y_true == c)\n",
    "        y_pred_bin = (y_pred == c)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_bin, y_pred_bin).ravel()\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "        specs.append(spec)\n",
    "    return float(np.nanmean(specs))\n",
    "\n",
    "def macro_auc_valid_classes(y_true: np.ndarray, y_proba: np.ndarray, class_order: np.ndarray):\n",
    "    aucs, skipped = [], []\n",
    "    for idx, c in enumerate(class_order):\n",
    "        y_true_bin = (y_true == c).astype(int)\n",
    "        pos = y_true_bin.sum()\n",
    "        neg = len(y_true_bin) - pos\n",
    "        if pos == 0 or neg == 0:\n",
    "            skipped.append(int(c))\n",
    "            continue\n",
    "        aucs.append(roc_auc_score(y_true_bin, y_proba[:, idx]))\n",
    "    if not aucs:\n",
    "        return np.nan, skipped\n",
    "    return float(np.mean(aucs)), skipped\n",
    "\n",
    "def sens_spec(y_true: np.ndarray, y_pred: np.ndarray, pos_label=None):\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    if classes.size == 2:\n",
    "        if pos_label is None:\n",
    "            pos_label = 1 if 1 in classes else classes.max()\n",
    "        neg_label = classes[0] if classes[1] == pos_label else classes[1]\n",
    "        sens = recall_score(y_true, y_pred, average=\"binary\", pos_label=pos_label, zero_division=0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[neg_label, pos_label]).ravel()\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "        return float(sens), float(spec)\n",
    "    else:\n",
    "        sens = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        spec = macro_specificity_ovr(y_true, y_pred)\n",
    "        return float(sens), float(spec)\n",
    "\n",
    "\n",
    "X_train_full_all101 = np.vstack([X_train_raw, X_val_raw])\n",
    "y_train_full = np.concatenate([y_train, y_val])\n",
    "X_test_all101 = X_test_raw\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_full_all101)\n",
    "X_test_scaled  = scaler.transform(X_test_all101)\n",
    "\n",
    "# Train MLP\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, 64), max_iter=500, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train_full)\n",
    "\n",
    "# Predict\n",
    "y_pred  = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)  # columns align with clf.classes_\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "sens, spec = sens_spec(y_test, y_pred, pos_label=POS_LABEL_FOR_BINARY)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "auc_macro, skipped = macro_auc_valid_classes(y_test, y_proba, clf.classes_)\n",
    "if skipped:\n",
    "    print(f\"[all_101] AUC skipped classes (no pos/neg in y_test): {skipped}\")\n",
    "\n",
    "\n",
    "if np.unique(y_test).size == 2:\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    diff = abs(bal_acc - 0.5 * (sens + spec))\n",
    "    if diff > 1e-8:\n",
    "        print(f\"[WARN] Balanced acc mismatch by {diff:.3e}\")\n",
    "\n",
    "results_df = pd.DataFrame([{\n",
    "    \"Feature_Config\": \"all_101\",\n",
    "    \"AUC_macro\": auc_macro,\n",
    "    \"Accuracy\": acc,\n",
    "    \"Sensitivity\": sens,\n",
    "    \"Specificity\": spec,\n",
    "    \"F1_macro\": f1_macro,\n",
    "}])\n",
    "\n",
    "print(\"\\nResults (all_101 only):\\n\", results_df.to_string(index=False))\n",
    "results_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved results to: {os.path.abspath(OUT_CSV)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83d5d7-0cc2-48c2-8d8e-d00bcba757e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
